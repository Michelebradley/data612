{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "book_recs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lufil1tGjGqP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "9a04dc47-2d11-45e6-d9a0-86d891b38c8b"
      },
      "source": [
        "!pip install surprise"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: surprise in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.6/dist-packages (from surprise) (1.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.18.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aEOq4CJhOK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import surprise\n",
        "from surprise import SVD\n",
        "from surprise import Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import cross_validate\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from collections import defaultdict\n",
        "\n",
        "ratings = pd.read_csv('https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/ratings.csv')\n",
        "books = pd.read_csv('https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/books.csv')\n",
        "book_tags = pd.read_csv('https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/book_tags.csv')\n",
        "tag_names = pd.read_csv('https://raw.githubusercontent.com/zygmuntz/goodbooks-10k/master/tags.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k0lblVIlrMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "book_tags_m = book_tags.merge(tag_names, on = 'tag_id' )\n",
        "\n",
        "#removing some of the most common tags that do not indicate anything about the book itself (to-read, audio-book, wish-list)\n",
        "stk_list = ['to-read','favorites','owned', 'books-i-own', 'currently-reading', 'have', \n",
        "            'library', 'to-buy', 'kindle', 'owned-books', 'my-books', 'audiobook',\n",
        "            'my-library', 'audio', 'own-it', 'books', 'ebooks', 'audible', 'audio-book',\n",
        "            'default', 'ebook', 'audiobooks', 'ebooks', 'wish-list', 'audiobooks', 'i-own', \n",
        "            'borrowed', 'e-books', 'e-book', 'maybe', 'audio-book', 'audio-books']\n",
        "#clean dataset\n",
        "book_tags_m = book_tags_m[~book_tags_m['tag_name'].isin(stk_list)]\n",
        "book_tags_m = book_tags_m[~book_tags_m.tag_name.str.contains(\"read-in-\")]\n",
        "#merge tags to one value\n",
        "books_grouped_tags = book_tags_m.groupby('goodreads_book_id')['tag_name'].apply(' '.join).reset_index()\n",
        "books_grouped_tags['tag_name'] = books_grouped_tags['tag_name'].str.replace('-',' ')\n",
        "#merge dataframes\n",
        "tagged_books = pd.merge(books, books_grouped_tags, left_on='book_id', right_on='goodreads_book_id', how='inner')\n",
        "books_final = books_grouped_tags.merge( books[['goodreads_book_id', 'title', 'authors']], on = 'goodreads_book_id' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X59qWRPUo8i5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Perform Content Filtering Analysis using sklearn TfidfVectorizer on book-tags\n",
        "tf1 = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0)\n",
        "matrix = tf1.fit_transform(books_final['tag_name'].head(10000))\n",
        "cosine_sim_tag = linear_kernel(matrix, matrix)\n",
        "\n",
        "#Perform Content Filtering Analysis using sklearn TfidfVectorizer on author\n",
        "tf2 = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0)\n",
        "matrix2 = tf2.fit_transform(books_final['title'].head(10000))\n",
        "cosine_sim_title = linear_kernel(matrix2, matrix2)\n",
        "\n",
        "#Perform Content Filtering Analysis using sklearn TfidfVectorizer on title\n",
        "tf3 = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0)\n",
        "matrix3 = tf3.fit_transform(books_final['authors'].head(10000))\n",
        "cosine_sim_author = linear_kernel(matrix3, matrix3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjCJ8ybchfo8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "adaee31f-9372-4ff0-ae32-7cf8897ea6e2"
      },
      "source": [
        "#Use Surprise to get SVD similarity\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(ratings[['user_id', 'book_id', 'rating']], reader)\n",
        "\n",
        "# sample random trainset and testset\n",
        "trainset, testset = train_test_split(data, test_size=.25)\n",
        "\n",
        "# We'll use the famous SVD algorithm.\n",
        "algo = SVD()\n",
        "\n",
        "# Train the algorithm on the trainset, and predict ratings for the testset\n",
        "algo.fit(trainset)\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Then compute RMSE\n",
        "accuracy.rmse(predictions)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.8347\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8346888335494874"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6jdV0QW7L2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_recs(predictions):\n",
        "     \n",
        "    top_recs = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_recs[iid].append((uid, est))\n",
        "     \n",
        "    return top_recs\n",
        "\n",
        "predictons_list_svd = get_recs(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4oA_lwm_lVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_final_rec(book_title, predictons_list_svd = predictons_list_svd, cosine_sim_tag = cosine_sim_tag, cosine_sim_title = cosine_sim_title, cosine_sim_author = cosine_sim_author):\n",
        "\n",
        "    book_id = books[books['title'] == book_title].book_id.iloc[0]\n",
        "\n",
        "    book = {k: v for k, v in predictons_list_svd.items() if k == book_id}\n",
        "    pred = book.get(book_id)\n",
        "\n",
        "    lst_books = [item[0] for item in pred]\n",
        "    lst_pred = [item[1] for item in pred]\n",
        "    svd_ratings_svd = pd.DataFrame(list(zip(lst_books, lst_pred)), columns =['books', 'pred_svd'])\n",
        "\n",
        "    sim_scores = list(enumerate(cosine_sim_tag[book_id]))\n",
        "    lst_books_tag = [item[0] for item in sim_scores]\n",
        "    lst_pred_tag = [item[1] for item in sim_scores]\n",
        "    svd_ratings_sim_tag = pd.DataFrame(list(zip(lst_books_tag, lst_pred_tag)), columns =['books', 'pred_sim_tag'])\n",
        "\n",
        "    sim_scores = list(enumerate(cosine_sim_title[book_id]))\n",
        "    lst_books_tag = [item[0] for item in sim_scores]\n",
        "    lst_pred_tag = [item[1] for item in sim_scores]\n",
        "    svd_ratings_sim_title = pd.DataFrame(list(zip(lst_books_tag, lst_pred_tag)), columns =['books', 'pred_sim_title'])\n",
        "\n",
        "    sim_scores = list(enumerate(cosine_sim_author[book_id]))\n",
        "    lst_books_tag = [item[0] for item in sim_scores]\n",
        "    lst_pred_tag = [item[1] for item in sim_scores]\n",
        "    svd_ratings_sim_auth = pd.DataFrame(list(zip(lst_books_tag, lst_pred_tag)), columns =['books', 'pred_sim_auth'])\n",
        "\n",
        "    merged_prediction1 = svd_ratings_svd.merge(svd_ratings_sim_tag, on = 'books')\n",
        "    merged_prediction2 = merged_prediction1.merge(svd_ratings_sim_title, on = 'books')\n",
        "    merged_prediction = merged_prediction2.merge(svd_ratings_sim_auth, on = 'books')\n",
        "    merged_prediction['final_prediction'] = merged_prediction['pred_svd'] * merged_prediction['pred_sim_tag'] * merged_prediction['pred_sim_title'] * merged_prediction['pred_sim_auth']\n",
        "    book_rec = merged_prediction[merged_prediction['final_prediction']==merged_prediction['final_prediction'].max()].books.iloc[0]\n",
        "\n",
        "    return print (\"If you like \" + book_title + \" then you may also like: \" + books[books['book_id'] == book_rec].title.iloc[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oV9_gdAexRv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3548a58d-bf90-4090-bd3b-498680d93d4b"
      },
      "source": [
        "get_final_rec(\"Slaughterhouse-Five\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "If you like Slaughterhouse-Five then you may also like: Where Eagles Dare \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abvGh527f85e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}