{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project5",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhuEjRzhNB2u",
        "colab_type": "text"
      },
      "source": [
        "The goal of this project is give you practice beginning to work with a distributed recommender system.\n",
        "\n",
        "It is sufficient for this assignment to build out your application on a single node.\n",
        "\n",
        "Adapt one of your recommendation systems to work with Apache Spark and compare\n",
        "the performance with your previous iteration. Consider the efficiency of the system and the added complexity of using Spark. You may complete the assignment using PySpark (Python), SparkR (R) , sparklyr (R), or Scala.\n",
        "\n",
        "Please include in your conclusion: For your given recommender system’s data,\n",
        "algorithm(s), and (envisioned) implementation, at what point would you see moving to a distributed platform such as Spark becoming necessary?\n",
        "\n",
        "This project, uses data from kaggle: https://www.kaggle.com/uciml/restaurant-data-with-consumer-ratings/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8z3vZkTdv_G",
        "colab_type": "code",
        "outputId": "eb8cdade-fe76-4cc0-9af0-0ff8920b61de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "!pip install pyspark\n",
        "!java -version\n",
        "!sudo update-alternatives --config java\n",
        "!java -version\n",
        "\n",
        "!apt-get install -y openjdk-8-jdk-headless -qq > /dev/null #install openjdk\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\" #set environment variable\n",
        "!java -version #check java version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (2.4.5)\n",
            "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.7)\n",
            "openjdk version \"11.0.6\" 2020-01-14\n",
            "OpenJDK Runtime Environment (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1, mixed mode, sharing)\n",
            "There are 2 choices for the alternative java (providing /usr/bin/java).\n",
            "\n",
            "  Selection    Path                                            Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      auto mode\n",
            "  1            /usr/lib/jvm/java-11-openjdk-amd64/bin/java      1111      manual mode\n",
            "  2            /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java   1081      manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: \n",
            "openjdk version \"11.0.6\" 2020-01-14\n",
            "OpenJDK Runtime Environment (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1, mixed mode, sharing)\n",
            "openjdk version \"11.0.6\" 2020-01-14\n",
            "OpenJDK Runtime Environment (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.6+10-post-Ubuntu-1ubuntu118.04.1, mixed mode, sharing)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hj3lVQ7kNmP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from pyspark.context import SparkContext\n",
        "from pyspark.sql.session import SparkSession\n",
        "sc = SparkContext('local')\n",
        "spark = SparkSession(sc)\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.types import IntegerType"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaxSnskNpQO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "schema = StructType([StructField(\"userID\", IntegerType(), True),StructField(\"placeID\", IntegerType(), True),StructField(\"rating\", IntegerType(), True)])\n",
        "\n",
        "#import data\n",
        "restaurants = pd.read_csv('rating_final.csv')\n",
        "restaurants['placeID'] = restaurants['placeID'].astype(int)\n",
        "\n",
        "sp_df = spark.createDataFrame(restaurants, schema=schema)\n",
        "data_df = sp_df.withColumn(\"placeID\", sp_df[\"placeID\"].cast(IntegerType()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcvHSZn1lV-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql import Row\n",
        "\n",
        "(training, test) = sp_df.randomSplit([0.8, 0.2])\n",
        "als = ALS(maxIter=5, regParam=0.01, userCol=\"userID\", itemCol=\"placeID\", ratingCol=\"rating\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1IdGakPqhqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "als = ALS(maxIter=5, regParam=0.01, userCol=\"userID\", itemCol=\"placeID\", ratingCol=\"rating\",\n",
        "          coldStartStrategy=\"drop\")\n",
        "model = als.fit(training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3gBfMAW80Y_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a30f497-663d-4f3f-832e-366961023496"
      },
      "source": [
        "#https://spark.apache.org/docs/2.2.0/ml-collaborative-filtering.html\n",
        "# Evaluate the model by computing the RMSE on the test data\n",
        "predictions = model.transform(test)\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
        "                                predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root-mean-square error = \" + str(rmse))\n",
        "\n",
        "# Generate top 10 movie recommendations for each user\n",
        "userRecs = model.recommendForAllUsers(10)\n",
        "# Generate top 10 user recommendations for each restaurant\n",
        "placeRecs = model.recommendForAllItems(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Root-mean-square error = 1.1716398312294891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYpS6ZFq84T4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "020877e8-a026-4585-89a5-22622900a967"
      },
      "source": [
        "#previous method\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "user_matrix = restaurants.pivot(index='UserID', columns='placeID', values='rating')\n",
        "\n",
        "TRAIN_SIZE = 0.80\n",
        "msk = np.random.rand(len(user_matrix)) < TRAIN_SIZE\n",
        "\n",
        "train = user_matrix[msk]  \n",
        "test = user_matrix[~msk]\n",
        "average = train.unstack().mean()\n",
        "SE = (test - average)*(test - average)\n",
        "MSE = SE.mean().mean()\n",
        "RMSE = MSE ** (1/2)\n",
        "\"RMSE is \" + str(RMSE)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RMSE is 0.7709595972198889'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBSI0sD7-DzN",
        "colab_type": "text"
      },
      "source": [
        "For your given recommender system’s data, algorithm(s), and (envisioned) implementation, at what point would you see moving to a distributed platform such as Spark becoming necessary?\n",
        "\n",
        "As datasets become bigger and more difficult to manage, the fact that spark is incredibly fast and can cache data allows for the possibility of running large recommender systems such as this one. "
      ]
    }
  ]
}